## ğŸ¯ Transformer Modelleri ve GeliÅŸmiÅŸ NLP UygulamalarÄ±

<p align="center">
  <b>BERT, T5, GPT ve diÄŸer Transformer modelleri ile endÃ¼stri standardÄ± NLP uygulamalarÄ± geliÅŸtirme!</b>
</p>

```mermaid
flowchart TD
    style A1 fill:#E8F6F3,stroke:#1B8E6B,stroke-width:2px
    style B1 fill:#FEF9E7,stroke:#D68910,stroke-width:2px
    style B2 fill:#EBF5FB,stroke:#2874A6,stroke-width:2px
    style B3 fill:#FADBD8,stroke:#C0392B,stroke-width:2px
    style B4 fill:#E8DAEF,stroke:#8E44AD,stroke-width:2px
    style B5 fill:#D6EAF8,stroke:#2980B9,stroke-width:2px
    style B6 fill:#FDEBD0,stroke:#CA6F1E,stroke-width:2px
    style B7 fill:#F0F3FF,stroke:#4A69BD,stroke-width:2px
    style B8 fill:#E8F8F5,stroke:#17A2B8,stroke-width:2px
    style B9 fill:#FFF2CC,stroke:#F39C12,stroke-width:2px
    style B10 fill:#E1F5FE,stroke:#0277BD,stroke-width:2px
    style Z1 fill:#F8F9FA,stroke:#6C757D,stroke-width:2px

    A1([ğŸ¤– Transformer Ekosistemi])
    B1([ğŸ­ Duygu Analizi<br><i>Sentiment Analysis</i>])
    B2([ğŸ·ï¸ SÄ±fÄ±r-AtÄ±ÅŸ SÄ±nÄ±flandÄ±rma<br><i>Zero-Shot Classification</i>])
    B3([âœï¸ Metin Ãœretimi<br><i>Text Generation</i>])
    B4([ğŸ¯ Maskeli Kelime Tahmini<br><i>Fill-Mask</i>])
    B5([ğŸ” AdlandÄ±rÄ±lmÄ±ÅŸ VarlÄ±k TanÄ±ma<br><i>NER</i>])
    B6([â“ Soru-Cevap Sistemleri<br><i>Q&A: BERT & T5</i>])
    B7([ğŸ“ Metin Ã–zetleme<br><i>Extractive & Abstractive</i>])
    B8([ğŸŒ Makine Ã‡evirisi<br><i>Translation</i>])
    B9([ğŸ’¬ Chatbot GeliÅŸtirme<br><i>OpenAI API</i>])
    B10([ğŸ“Š Model DeÄŸerlendirme<br><i>Performance Analysis</i>])
    Z1([ğŸš€ GerÃ§ek DÃ¼nya UygulamalarÄ±])

    A1 --> B1
    A1 --> B2
    A1 --> B3
    A1 --> B4
    A1 --> B5
    A1 --> B6
    A1 --> B7
    A1 --> B8
    A1 --> B9
    B1 --> B10
    B2 --> B10
    B3 --> B10
    B4 --> B10
    B5 --> B10
    B6 --> B10
    B7 --> B10
    B8 --> B10
    B9 --> B10
    B10 --> Z1

    B3 -.-> B9
    B6 -.-> B9
    B7 -.-> B6
```

---

## ğŸ“Š Proje Ã–zeti

Bu klasÃ¶rde, **Hugging Face Transformers** ekosistemi kullanÄ±larak modern NLP'nin en kritik gÃ¶revleri Ã¼zerinde Ã§alÄ±ÅŸÄ±lmaktadÄ±r. 
Projeler, BERT, T5, GPT, BART gibi state-of-the-art modelleri kullanarak duygu analizinden chatbot geliÅŸtirmeye kadar geniÅŸ bir yelpazede pratik uygulamalar iÃ§ermektedir.

### Ana Konular:
- **Pipeline API**: HÄ±zlÄ± prototipleme ve model kullanÄ±mÄ±
- **BERT TabanlÄ± Modeller**: Ekstraktif soru-cevaplama ve token classification
- **T5 ve BART**: Generatif gÃ¶revler ve metin Ã¶zetleme
- **GPT Modelleri**: Metin Ã¼retimi ve tamamlama
- **OpenAI API**: Profesyonel chatbot geliÅŸtirme
- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**: Ekstraktif vs Abstraktif yaklaÅŸÄ±mlar

---

## ğŸŒŸ DetaylÄ± Ã‡alÄ±ÅŸma AÅŸamalarÄ± & Flashcardlar

### 1. **ğŸ­ Duygu Analizi (Sentiment Analysis)**
- **AmaÃ§:** Metinlerin duygusal tonunu (pozitif/negatif/nÃ¶tr) otomatik olarak belirleme.
- **Model:** DistilBERT (SST-2 Ã¼zerinde fine-tuned)
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Pipeline oluÅŸturma
  classifier = pipeline("sentiment-analysis")
  
  # Duygu analizi yapma
  sonuc = classifier("I love this product! It's amazing!")
  print(sonuc)
  # Output: [{'label': 'POSITIVE', 'score': 0.9998}]
  
  # Ã‡oklu metin analizi
  metinler = [
      "This is the best day ever!",
      "I'm really disappointed with the service.",
      "The weather is okay."
  ]
  sonuclar = classifier(metinler)
  for metin, sonuc in zip(metinler, sonuclar):
      print(f"{metin} â†’ {sonuc['label']} ({sonuc['score']:.2%})")
  ```
- <div style="border:1px solid #D68910; border-radius:8px; padding:12px; background:#FEF9E7; margin:10px 0;">
  <b>Soru:</b> Pipeline API'nin geleneksel model yÃ¼kleme yÃ¶ntemlerine gÃ¶re avantajlarÄ± nelerdir?<br>
  <b>Cevap:</b> Pipeline API, tokenizer, model ve post-processing adÄ±mlarÄ±nÄ± tek satÄ±rda otomatikleÅŸtirir, kod karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±r ve hÄ±zlÄ± prototipleme saÄŸlar.
  </div>

---

### 2. **ğŸ·ï¸ SÄ±fÄ±r-AtÄ±ÅŸ SÄ±nÄ±flandÄ±rma (Zero-Shot Classification)**
- **AmaÃ§:** Ã–nceden eÄŸitilmemiÅŸ kategorilerde metin sÄ±nÄ±flandÄ±rma yapabilme.
- **Model:** facebook/bart-large-mnli
- **KullanÄ±m AlanlarÄ±:** Dinamik kategori yÃ¶netimi, esneklik gerektiren sistemler
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Zero-shot classifier oluÅŸturma
  classifier = pipeline("zero-shot-classification", 
                       model="facebook/bart-large-mnli")
  
  # Metin ve olasÄ± kategoriler
  metin = "The new iPhone has an amazing camera and long battery life."
  kategoriler = ["technology", "politics", "sports", "entertainment", "health"]
  
  # SÄ±nÄ±flandÄ±rma
  sonuc = classifier(metin, candidate_labels=kategoriler)
  
  print(f"En olasÄ± kategori: {sonuc['labels'][0]} ({sonuc['scores'][0]:.2%})")
  for label, score in zip(sonuc['labels'], sonuc['scores']):
      print(f"  {label}: {score:.2%}")
  ```
- <div style="border:1px solid #2874A6; border-radius:8px; padding:12px; background:#EBF5FB; margin:10px 0;">
  <b>Soru:</b> Zero-shot classification'Ä±n geleneksel supervised learning'e gÃ¶re avantajÄ± nedir?<br>
  <b>Cevap:</b> Her yeni kategori iÃ§in model yeniden eÄŸitmek yerine, kategorileri dinamik olarak belirleyebilir ve hemen kullanabilirsiniz. EÄŸitim verisi gerektirmez.
  </div>

---

### 3. **âœï¸ Metin Ãœretimi (Text Generation)**
- **AmaÃ§:** Verilen bir prompt'a dayanarak tutarlÄ± ve anlamlÄ± metin Ã¼retme.
- **Modeller:** GPT-2, DistilGPT2, GPT-Neo
- **Parametreler:**
  - `max_length`: Toplam Ã§Ä±ktÄ± uzunluÄŸu
  - `temperature`: YaratÄ±cÄ±lÄ±k seviyesi (0.7-1.0 arasÄ± optimal)
  - `top_k`: En olasÄ± k kelime havuzu
  - `top_p`: Nucleus sampling (kÃ¼mÃ¼latif olasÄ±lÄ±k)
  - `num_return_sequences`: KaÃ§ farklÄ± varyasyon
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Text generation pipeline
  generator = pipeline("text-generation", model="distilgpt2")
  
  # Prompt ile metin Ã¼retimi
  prompt = "In this course, we will teach you how to"
  
  sonuclar = generator(
      prompt,
      max_length=50,           # Maksimum 50 token
      num_return_sequences=3,  # 3 farklÄ± varyasyon
      temperature=0.8,         # Orta seviye yaratÄ±cÄ±lÄ±k
      top_k=50,               # Top 50 kelime havuzu
      top_p=0.95,             # %95 olasÄ±lÄ±k eÅŸiÄŸi
      do_sample=True          # Deterministik deÄŸil
  )
  
  for i, sonuc in enumerate(sonuclar, 1):
      print(f"Varyasyon {i}: {sonuc['generated_text']}")
  ```
- <div style="border:1px solid #C0392B; border-radius:8px; padding:12px; background:#FADBD8; margin:10px 0;">
  <b>Soru:</b> Temperature parametresinin 0.1 ve 1.5 deÄŸerlerindeki etkileri nedir?<br>
  <b>Cevap:</b> Temperature=0.1: DÃ¼ÅŸÃ¼k Ã§eÅŸitlilik, deterministik, gÃ¼venli seÃ§imler. Temperature=1.5: YÃ¼ksek Ã§eÅŸitlilik, yaratÄ±cÄ± ama bazen anlamsÄ±z sonuÃ§lar.
  </div>

---

### 4. **ğŸ¯ Maskeli Kelime Tahmini (Fill-Mask)**
- **AmaÃ§:** CÃ¼mlelerdeki maskelenmiÅŸ kelimeleri baÄŸlamdan tahmin etme.
- **Modeller:** BERT, RoBERTa, DistilBERT, ALBERT
- **KullanÄ±m AlanlarÄ±:** Otomatik tamamlama, yazÄ±m denetimi, veri arttÄ±rma
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Fill-mask pipeline (BERT-base-cased)
  unmasker = pipeline("fill-mask", model="bert-base-cased")
  
  # Maskeli cÃ¼mle
  cumle = "The capital of France is [MASK]."
  
  # Tahminleri alma (top 5)
  tahminler = unmasker(cumle, top_k=5)
  
  print(f"CÃ¼mle: {cumle}\n")
  for i, tahmin in enumerate(tahminler, 1):
      kelime = tahmin['token_str']
      skor = tahmin['score']
      tamamlanmis = tahmin['sequence']
      print(f"{i}. '{kelime}' - {skor:.2%}")
      print(f"   â†’ {tamamlanmis}")
  ```
- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:**

  | Model | AvantajÄ± | KullanÄ±m Durumu |
  |-------|----------|-----------------|
  | `bert-base-cased` | Standart, bÃ¼yÃ¼k-kÃ¼Ã§Ã¼k harf duyarlÄ± | Genel amaÃ§lÄ± |
  | `roberta-base` | BERT'ten optimize, daha iyi performans | YÃ¼ksek doÄŸruluk |
  | `distilbert-base` | %40 kÃ¼Ã§Ã¼k, %60 hÄ±zlÄ± | HÄ±z kritik |
  | `xlm-roberta-base` | 100+ dil desteÄŸi | Ã‡ok dilli |

- <div style="border:1px solid #8E44AD; border-radius:8px; padding:12px; background:#E8DAEF; margin:10px 0;">
  <b>Soru:</b> Fill-mask modellerinin masked language modeling ile eÄŸitilmesinin avantajÄ± nedir?<br>
  <b>Cevap:</b> Model, kelimeleri Ã§ift yÃ¶nlÃ¼ (bidirectional) baÄŸlamla Ã¶ÄŸrenir, hem Ã¶nceki hem sonraki kelimeleri dikkate alÄ±r, bu da daha doÄŸru tahminler saÄŸlar.
  </div>

---

### 5. **ğŸ” AdlandÄ±rÄ±lmÄ±ÅŸ VarlÄ±k TanÄ±ma (Named Entity Recognition - NER)**
- **AmaÃ§:** Metinlerdeki Ã¶zel isimleri (kiÅŸi, yer, organizasyon, tarih) tespit etme.
- **Model:** dbmdz/bert-large-cased-finetuned-conll03-english
- **VarlÄ±k Tipleri:** PER (Person), LOC (Location), ORG (Organization), MISC (Miscellaneous)
- **Kod:**
  ```python
  from transformers import pipeline
  
  # NER pipeline
  ner = pipeline("ner", grouped_entities=True)
  
  # Metin analizi
  metin = """
  Elon Musk announced that Tesla will open a new factory in Berlin, Germany.
  The company also plans to expand operations in China and the United States.
  """
  
  varliklar = ner(metin)
  
  for varlik in varliklar:
      print(f"{varlik['word']} â†’ {varlik['entity_group']} ({varlik['score']:.2%})")
  
  # Output:
  # Elon Musk â†’ PER (99.8%)
  # Tesla â†’ ORG (99.5%)
  # Berlin â†’ LOC (99.9%)
  # Germany â†’ LOC (99.7%)
  # China â†’ LOC (99.6%)
  # United States â†’ LOC (99.8%)
  ```
- <div style="border:1px solid #2980B9; border-radius:8px; padding:12px; background:#D6EAF8; margin:10px 0;">
  <b>Soru:</b> NER'in bilgi Ã§Ä±karÄ±mÄ± (information extraction) sistemlerinde rolÃ¼ nedir?<br>
  <b>Cevap:</b> NER, yapÄ±landÄ±rÄ±lmamÄ±ÅŸ metinden Ã¶nemli varlÄ±klarÄ± otomatik olarak tespit ederek, veri tabanÄ± doldurma, bilgi grafiÄŸi oluÅŸturma ve iliÅŸki Ã§Ä±karÄ±mÄ± iÃ§in temel saÄŸlar.
  </div>

---

### 6. **â“ Soru-Cevap Sistemleri (Question Answering)**

#### ğŸ”¹ BERT ile Ekstraktif QA
- **YaklaÅŸÄ±m:** CevabÄ± verilen metinden doÄŸrudan Ã§Ä±karÄ±r
- **Model:** deepset/roberta-base-squad2
- **Kod:**
  ```python
  from transformers import pipeline
  
  # QA pipeline
  qa_pipeline = pipeline("question-answering")
  
  # Context ve soru
  context = """
  Hugging Face is a company founded in 2016 by ClÃ©ment Delangue, Julien Chaumond, 
  and Thomas Wolf. The company is based in New York City and Paris. Hugging Face 
  is best known for its Transformers library, which provides thousands of 
  pre-trained models for Natural Language Processing tasks.
  """
  
  soru = "When was Hugging Face founded?"
  
  # Cevap bulma
  sonuc = qa_pipeline(question=soru, context=context)
  
  print(f"Soru: {soru}")
  print(f"Cevap: {sonuc['answer']}")
  print(f"GÃ¼ven Skoru: {sonuc['score']:.2%}")
  print(f"Pozisyon: [{sonuc['start']}:{sonuc['end']}]")
  ```

#### ğŸ”¹ T5 ile Generatif QA
- **YaklaÅŸÄ±m:** CevabÄ± kendi kelimelerle Ã¼retir
- **Model:** t5-base
- **Kod:**
  ```python
  from transformers import T5Tokenizer, T5ForConditionalGeneration
  
  # Model ve tokenizer yÃ¼kleme
  model_name = "t5-base"
  tokenizer = T5Tokenizer.from_pretrained(model_name)
  model = T5ForConditionalGeneration.from_pretrained(model_name)
  
  # T5 iÃ§in input formatÄ±: "question: SORU context: CONTEXT"
  input_text = f"question: {soru} context: {context}"
  
  # Tokenization
  inputs = tokenizer(input_text, return_tensors="pt", max_length=512, truncation=True)
  
  # Cevap Ã¼retme
  outputs = model.generate(**inputs, max_length=50, num_beams=4)
  cevap = tokenizer.decode(outputs[0], skip_special_tokens=True)
  
  print(f"T5 CevabÄ±: {cevap}")
  ```

- **BERT vs T5 KarÅŸÄ±laÅŸtÄ±rmasÄ±:**

  | Ã–zellik | BERT (Ekstraktif) | T5 (Generatif) |
  |---------|-------------------|----------------|
  | YaklaÅŸÄ±m | Metinden cevabÄ± kopyalar | CevabÄ± yeniden Ã¼retir |
  | Esneklik | Context'te olmalÄ± | Daha esnek cevaplar |
  | HÄ±z | Daha hÄ±zlÄ± | Daha yavaÅŸ |
  | KullanÄ±m | Fact-based sorular | AÃ§Ä±klama gerektiren |

- <div style="border:1px solid #CA6F1E; border-radius:8px; padding:12px; background:#FDEBD0; margin:10px 0;">
  <b>Soru:</b> BERT'in token-level start/end prediction yapÄ±sÄ± nasÄ±l Ã§alÄ±ÅŸÄ±r?<br>
  <b>Cevap:</b> BERT, her token iÃ§in iki ayrÄ± skor Ã¼retir: baÅŸlangÄ±Ã§ olasÄ±lÄ±ÄŸÄ± ve bitiÅŸ olasÄ±lÄ±ÄŸÄ±. En yÃ¼ksek skorlara sahip start-end token Ã§ifti cevap olarak seÃ§ilir.
  </div>

---

### 7. **ğŸ“ Metin Ã–zetleme (Text Summarization)**

#### ğŸ”¹ Ekstraktif Ã–zetleme (Sumy KÃ¼tÃ¼phanesi)
- **YaklaÅŸÄ±m:** Metnin en Ã¶nemli cÃ¼mlelerini seÃ§er ve birleÅŸtirir
- **Algoritmalar:** LexRank, TextRank, LSA, Luhn
- **Kod:**
  ```python
  from sumy.parsers.plaintext import PlaintextParser
  from sumy.nlp.tokenizers import Tokenizer
  from sumy.summarizers.lex_rank import LexRankSummarizer
  
  # Uzun metin
  metin = """
  Artificial Intelligence has become one of the most transformative 
  technologies of the 21st century. Machine learning, a subset of AI, 
  enables computers to learn from data without being explicitly programmed. 
  Deep learning, which uses neural networks with multiple layers, has 
  revolutionized fields such as computer vision, natural language processing, 
  and speech recognition. Companies like Google, Amazon, and Microsoft are 
  investing billions of dollars in AI research and development.
  """
  
  # Parse etme
  parser = PlaintextParser.from_string(metin, Tokenizer("english"))
  
  # LexRank Ã¶zetleyici
  summarizer = LexRankSummarizer()
  summary = summarizer(parser.document, sentences_count=2)
  
  # Ã–zet metni
  ozet = ' '.join([str(sentence) for sentence in summary])
  print(f"Ã–zet: {ozet}")
  ```

#### ğŸ”¹ Abstraktif Ã–zetleme (Transformers)
- **YaklaÅŸÄ±m:** Metni anlar ve yeni cÃ¼mlelerle yeniden yazar
- **Modeller:** BART, T5, Pegasus
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Summarization pipeline (BART modeli)
  summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
  
  # Ã–zetleme
  ozet = summarizer(
      metin,
      max_length=130,      # Maksimum Ã¶zet uzunluÄŸu
      min_length=30,       # Minimum Ã¶zet uzunluÄŸu
      do_sample=False      # Deterministik Ã¶zet
  )
  
  print(f"BART Ã–zeti: {ozet[0]['summary_text']}")
  
  # SÄ±kÄ±ÅŸtÄ±rma oranÄ± hesaplama
  orijinal_kelime = len(metin.split())
  ozet_kelime = len(ozet[0]['summary_text'].split())
  sikistirma = (1 - ozet_kelime / orijinal_kelime) * 100
  print(f"SÄ±kÄ±ÅŸtÄ±rma OranÄ±: {sikistirma:.1f}%")
  ```

- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±:**

  | Model | GÃ¼Ã§lÃ¼ YÃ¶nÃ¼ | KullanÄ±m AlanÄ± |
  |-------|------------|----------------|
  | `facebook/bart-large-cnn` | CNN/DailyMail iÃ§in optimize | Haber Ã¶zetleme |
  | `t5-base` | Multi-task, genel amaÃ§lÄ± | Ã‡eÅŸitli metin tipleri |
  | `google/pegasus-xsum` | Abstractive, tek cÃ¼mle | KÄ±sa Ã¶zetler |
  | Sumy LexRank | HÄ±zlÄ±, aÃ§Ä±klanabilir | Ekstraktif, basit |

- <div style="border:1px solid #4A69BD; border-radius:8px; padding:12px; background:#F0F3FF; margin:10px 0;">
  <b>Soru:</b> Ekstraktif ve abstraktif Ã¶zetleme arasÄ±ndaki temel fark ve hangisinin ne zaman tercih edileceÄŸi?<br>
  <b>Cevap:</b> Ekstraktif: Orijinal cÃ¼mleleri seÃ§er, daha gÃ¼venilir ama sert geÃ§iÅŸler olabilir. Abstraktif: Yeni cÃ¼mleler Ã¼retir, daha akÄ±cÄ± ama halÃ¼sinasyon riski var. FaktÃ¼el doÄŸruluk iÃ§in ekstraktif, akÄ±cÄ±lÄ±k iÃ§in abstraktif tercih edilir.
  </div>

---

### 8. **ğŸŒ Makine Ã‡evirisi (Machine Translation)**
- **AmaÃ§:** Metinleri bir dilden diÄŸerine otomatik Ã§evirme.
- **Model:** Helsinki-NLP modelleri (200+ dil Ã§ifti)
- **Mimari:** MarianMT (Transformer tabanlÄ±)
- **Kod:**
  ```python
  from transformers import pipeline
  
  # Ä°ngilizce â†’ FransÄ±zca Ã§eviri
  translator_en_fr = pipeline("translation_en_to_fr", 
                              model="Helsinki-NLP/opus-mt-en-fr")
  
  # Ã‡eviri yapma
  metin = "Hello, how are you? I hope you're having a great day!"
  ceviri = translator_en_fr(metin)
  print(f"EN: {metin}")
  print(f"FR: {ceviri[0]['translation_text']}")
  
  # Ã‡oklu dil desteÄŸi
  # Ä°ngilizce â†’ Almanca
  translator_en_de = pipeline("translation_en_to_de",
                              model="Helsinki-NLP/opus-mt-en-de")
  
  # Ä°ngilizce â†’ Ä°spanyolca
  translator_en_es = pipeline("translation_en_to_es",
                              model="Helsinki-NLP/opus-mt-en-es")
  ```
- **PopÃ¼ler Dil Ã‡iftleri:**
  - `Helsinki-NLP/opus-mt-en-fr`: English â†’ French
  - `Helsinki-NLP/opus-mt-en-de`: English â†’ German
  - `Helsinki-NLP/opus-mt-en-es`: English â†’ Spanish
  - `Helsinki-NLP/opus-mt-en-zh`: English â†’ Chinese
  - `Helsinki-NLP/opus-mt-tr-en`: Turkish â†’ English

- <div style="border:1px solid #17A2B8; border-radius:8px; padding:12px; background:#E8F8F5; margin:10px 0;">
  <b>Soru:</b> Transformer tabanlÄ± Ã§eviri modellerinin Ã¶nceki RNN/LSTM modellerine gÃ¶re Ã¼stÃ¼nlÃ¼kleri nelerdir?<br>
  <b>Cevap:</b> Attention mechanism ile uzun menzilli baÄŸÄ±mlÄ±lÄ±klarÄ± daha iyi yakalar, paralelleÅŸtirme ile hÄ±zlÄ±dÄ±r, ve baÄŸlamÄ± daha iyi anlayarak daha doÄŸru Ã§eviriler Ã¼retir.
  </div>

---

### 9. **ğŸ’¬ Chatbot GeliÅŸtirme (OpenAI API)**
- **AmaÃ§:** KonuÅŸma geÃ§miÅŸini takip eden, baÄŸlam farkÄ±nda chatbot oluÅŸturma.
- **API:** OpenAI GPT-3.5-turbo / GPT-4
- **Ã–zellikler:** 
  - KonuÅŸma geÃ§miÅŸi yÃ¶netimi
  - System prompt ile davranÄ±ÅŸ belirleme
  - Streaming yanÄ±tlar
- **Kod:**
  ```python
  import openai
  
  # OpenAI Client oluÅŸturma
  client = openai.OpenAI(api_key="YOUR-API-KEY")
  
  def chat_with_gpt(history_list):
      """
      KonuÅŸma geÃ§miÅŸiyle GPT'ye istek gÃ¶nder
      
      Args:
          history_list: [{"role": "user/assistant/system", "content": "..."}]
      
      Returns:
          str: GPT'nin yanÄ±tÄ±
      """
      response = client.chat.completions.create(
          model="gpt-3.5-turbo",
          messages=history_list
      )
      return response.choices[0].message.content.strip()
  
  # Chatbot dÃ¶ngÃ¼sÃ¼
  if __name__ == "__main__":
      # KonuÅŸma geÃ§miÅŸi
      history_list = [
          {"role": "system", "content": "You are a helpful assistant."}
      ]
      
      print("Chatbot baÅŸlatÄ±ldÄ±! (Ã‡Ä±kmak iÃ§in 'exit' yazÄ±n)\n")
      
      while True:
          # KullanÄ±cÄ± girdisi
          user_input = input("You: ")
          
          if user_input.lower() in ["exit", "q", "quit"]:
              print("KonuÅŸma sonlandÄ±rÄ±ldÄ±.")
              break
          
          # KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe ekle
          history_list.append({"role": "user", "content": user_input})
          
          # GPT'den yanÄ±t al
          response = chat_with_gpt(history_list)
          print(f"ChatGPT: {response}\n")
          
          # Asistan yanÄ±tÄ±nÄ± geÃ§miÅŸe ekle
          history_list.append({"role": "assistant", "content": response})
  ```

- **System Prompt Ã–rnekleri:**
  ```python
  # Teknik destek botu
  {"role": "system", "content": "You are a technical support specialist. Be helpful, patient, and provide step-by-step solutions."}
  
  # EÄŸitim asistanÄ±
  {"role": "system", "content": "You are a patient teacher. Explain concepts clearly with examples and analogies."}
  
  # Kod inceleme asistanÄ±
  {"role": "system", "content": "You are an expert code reviewer. Provide constructive feedback on code quality, best practices, and potential bugs."}
  ```

- **GeliÅŸmiÅŸ Ã–zellikler:**
  ```python
  # Temperature kontrolÃ¼ (yaratÄ±cÄ±lÄ±k)
  response = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=history_list,
      temperature=0.7,  # 0.0-2.0 arasÄ± (0=deterministik, 2=Ã§ok yaratÄ±cÄ±)
      max_tokens=500,   # Maksimum yanÄ±t uzunluÄŸu
      top_p=0.9,        # Nucleus sampling
      frequency_penalty=0.5,  # Tekrar azaltma
      presence_penalty=0.5    # Konu Ã§eÅŸitliliÄŸi
  )
  ```

- <div style="border:1px solid #F39C12; border-radius:8px; padding:12px; background:#FFF2CC; margin:10px 0;">
  <b>Soru:</b> KonuÅŸma geÃ§miÅŸi yÃ¶netiminin chatbot performansÄ± Ã¼zerindeki etkisi nedir?<br>
  <b>Cevap:</b> KonuÅŸma geÃ§miÅŸi, modelin baÄŸlamÄ± anlamasÄ±nÄ± saÄŸlar, tutarlÄ± yanÄ±tlar verir ve Ã¶nceki mesajlara referans verebilir. Ancak token limiti nedeniyle eski mesajlarÄ± budamak gerekebilir.
  </div>

---

### 10. **ğŸ“ˆ Model DeÄŸerlendirme ve Optimizasyon**
- **Metrikler:**
  - **Duygu Analizi**: Accuracy, Precision, Recall, F1-Score
  - **Soru-Cevap**: Exact Match, F1-Score
  - **Ã–zetleme**: ROUGE-1, ROUGE-2, ROUGE-L
  - **Ã‡eviri**: BLEU Score
- **Performans Ä°zleme:**
  ```python
  import time
  
  # Ä°nferans sÃ¼resi Ã¶lÃ§Ã¼mÃ¼
  start_time = time.time()
  sonuc = classifier("Test metni")
  end_time = time.time()
  
  print(f"Ä°nferans sÃ¼resi: {(end_time - start_time)*1000:.2f} ms")
  
  # Batch iÅŸleme ile optimizasyon
  metinler = ["metin1", "metin2", "metin3", ...]
  sonuclar = classifier(metinler, batch_size=8)  # Daha hÄ±zlÄ±
  ```

- <div style="border:1px solid #0277BD; border-radius:8px; padding:12px; background:#E1F5FE; margin:10px 0;">
  <b>Soru:</b> Model seÃ§iminde doÄŸruluk dÄ±ÅŸÄ±nda hangi faktÃ¶rler Ã¶nemlidir?<br>
  <b>Cevap:</b> Ä°nferans hÄ±zÄ±, model boyutu (deployment), bellek kullanÄ±mÄ±, dil desteÄŸi, fine-tuning kolaylÄ±ÄŸÄ± ve maliyet. Ãœretim ortamÄ±nda hÄ±z-doÄŸruluk trade-off'u kritiktir.
  </div>

---

## ğŸ“‚ KlasÃ¶r Ä°Ã§eriÄŸi

- `01_transformers.ipynb` : Transformers kÃ¼tÃ¼phanesi ile 9 farklÄ± NLP gÃ¶revi (Sentiment, Zero-Shot, Generation, Fill-Mask, NER, Q&A, Summarization, Translation)
- `02_qa_bert_t5_metinozet.ipynb` : BERT ve T5 ile soru-cevaplama sistemleri, ekstraktif ve abstraktif metin Ã¶zetleme
- `03_chatbot_prototype.ipynb` : OpenAI API kullanarak profesyonel chatbot geliÅŸtirme

---

## ğŸ”§ Teknik Gereksinimler

```python
# Transformers Ekosistemi
transformers >= 4.30.0
torch >= 2.0.0
datasets >= 2.14.0
evaluate >= 0.4.0
sentencepiece >= 0.1.99

# Metin Ã–zetleme
sumy >= 0.11.0
rouge-score >= 0.1.2

# NLP Temelleri
nltk >= 3.8.0

# Veri Ä°ÅŸleme
pandas >= 2.0.0
numpy >= 1.24.0

# GÃ¶rselleÅŸtirme
matplotlib >= 3.7.0
seaborn >= 0.12.0

# OpenAI API
openai >= 1.0.0
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. **Ortam HazÄ±rlÄ±ÄŸÄ±:**
```bash
pip install transformers torch datasets evaluate sentencepiece
pip install sumy nltk rouge-score
pip install openai
pip install pandas numpy matplotlib seaborn
```

### 2. **NLTK Veri Ä°ndirme:**
```python
import nltk
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
```

### 3. **Ä°lk Pipeline KullanÄ±mÄ±:**
```python
from transformers import pipeline

# Duygu analizi
classifier = pipeline("sentiment-analysis")
print(classifier("I love transformers!"))

# Soru-cevap
qa = pipeline("question-answering")
result = qa(
    question="What is NLP?",
    context="Natural Language Processing (NLP) is a field of AI."
)
print(result['answer'])

# Metin Ã¶zetleme
summarizer = pipeline("summarization")
summary = summarizer("Long text here...", max_length=50)
print(summary[0]['summary_text'])
```

### 4. **OpenAI API Kurulumu:**
```python
import openai

client = openai.OpenAI(api_key="your-api-key-here")

response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
print(response.choices[0].message.content)
```

---

## ğŸ“Š Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### Duygu Analizi Modelleri

| Model | Accuracy | HÄ±z | Boyut | KullanÄ±m AlanÄ± |
|-------|----------|-----|-------|----------------|
| `distilbert-base-uncased-finetuned-sst-2-english` | ~91% | HÄ±zlÄ± | 66M | Genel amaÃ§lÄ± |
| `roberta-base` | ~94% | Orta | 125M | YÃ¼ksek doÄŸruluk |
| `bert-base-multilingual-uncased-sentiment` | ~88% | Orta | 110M | Ã‡ok dilli |

### Soru-Cevaplama Modelleri

| Model | F1 Score | Exact Match | Ã–zellik |
|-------|----------|-------------|---------|
| `deepset/roberta-base-squad2` | ~87 | ~79 | SQuAD 2.0 Ã¼zerinde eÄŸitilmiÅŸ |
| `bert-large-uncased-whole-word-masking-finetuned-squad` | ~93 | ~86 | BERT-large, yÃ¼ksek doÄŸruluk |
| `t5-base` (generative) | - | - | Esnek cevaplar Ã¼retir |

### Ã–zetleme Modelleri

| Model | ROUGE-1 | ROUGE-L | SÄ±kÄ±ÅŸtÄ±rma | YaklaÅŸÄ±m |
|-------|---------|---------|------------|----------|
| Sumy LexRank | ~40 | ~35 | %60-70 | Ekstraktif |
| `facebook/bart-large-cnn` | ~44 | ~40 | %70-80 | Abstraktif |
| `google/pegasus-xsum` | ~47 | ~44 | %80-90 | Abstraktif, agresif |
| `t5-base` | ~42 | ~38 | %70-75 | Abstraktif, genel |

---

## ğŸ’¡ Best Practices ve Ä°puÃ§larÄ±

### âœ… **Model SeÃ§imi:**
1. **HÄ±z Ã–ncelikli:** DistilBERT, DistilGPT2 gibi distilled modelleri tercih edin
2. **DoÄŸruluk Ã–ncelikli:** BERT-large, RoBERTa-large, T5-large kullanÄ±n
3. **Ã‡ok Dilli:** XLM-RoBERTa, mBERT tercih edin
4. **Kaynak KÄ±sÄ±tlÄ±:** ALBERT, DistilBERT gibi hafif modelleri seÃ§in

### âœ… **Pipeline Optimizasyonu:**
```python
# âŒ YavaÅŸ: Her Ã§aÄŸrÄ±da yeni pipeline
for text in texts:
    classifier = pipeline("sentiment-analysis")  # Tekrar tekrar yÃ¼kleme
    result = classifier(text)

# âœ… HÄ±zlÄ±: Pipeline'Ä± bir kez oluÅŸtur
classifier = pipeline("sentiment-analysis")
for text in texts:
    result = classifier(text)

# âœ… En HÄ±zlÄ±: Batch processing
classifier = pipeline("sentiment-analysis")
results = classifier(texts, batch_size=16)
```

### âœ… **Bellek YÃ¶netimi:**
```python
import torch

# GPU kullanÄ±mÄ±
device = 0 if torch.cuda.is_available() else -1
classifier = pipeline("sentiment-analysis", device=device)

# Model quantization (INT8) - %75 daha kÃ¼Ã§Ã¼k
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

model = AutoModelForSequenceClassification.from_pretrained(
    "distilbert-base-uncased-finetuned-sst-2-english",
    torch_dtype=torch.int8  # Quantization
)
```

### âœ… **API KullanÄ±mÄ± (OpenAI):**
```python
# Token limiti kontrolÃ¼
def trim_history(history, max_tokens=3000):
    """Eski mesajlarÄ± budayarak token limitini aÅŸma"""
    while estimate_tokens(history) > max_tokens:
        # System mesajÄ±nÄ± koru, en eski user/assistant mesajÄ± sil
        if len(history) > 1:
            history.pop(1)
    return history

# Rate limiting ve hata yÃ¶netimi
import time
from openai import RateLimitError

def safe_chat_request(messages, max_retries=3):
    for i in range(max_retries):
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=messages
            )
            return response.choices[0].message.content
        except RateLimitError:
            if i < max_retries - 1:
                time.sleep(2 ** i)  # Exponential backoff
            else:
                raise
```

---

## ğŸ¯ GerÃ§ek DÃ¼nya KullanÄ±m SenaryolarÄ±

### ğŸ“§ **E-posta Otomasyonu**
```python
# E-postayÄ± sÄ±nÄ±flandÄ±r ve Ã¶zetle
email_text = "Uzun e-posta iÃ§eriÄŸi..."

# 1. Kategori belirleme (Zero-shot)
category_classifier = pipeline("zero-shot-classification")
categories = ["urgent", "spam", "info", "sales", "support"]
category = category_classifier(email_text, categories)['labels'][0]

# 2. Duygu analizi
sentiment = pipeline("sentiment-analysis")(email_text)[0]['label']

# 3. Ã–zetleme
summary = pipeline("summarization")(email_text, max_length=50)[0]['summary_text']

print(f"Kategori: {category}")
print(f"Duygu: {sentiment}")
print(f"Ã–zet: {summary}")
```

### ğŸ« **MÃ¼ÅŸteri Destek Sistemi**
```python
# Destek bileti analizi
def analyze_support_ticket(ticket_text):
    # NER ile Ã¶nemli bilgileri Ã§Ä±kar
    ner = pipeline("ner", grouped_entities=True)
    entities = ner(ticket_text)
    
    # Duygu analizi
    sentiment = pipeline("sentiment-analysis")(ticket_text)[0]
    
    # Ã–ncelik belirleme
    priority_classifier = pipeline("zero-shot-classification")
    priority = priority_classifier(
        ticket_text, 
        ["critical", "high", "medium", "low"]
    )
    
    return {
        'entities': entities,
        'sentiment': sentiment,
        'priority': priority['labels'][0],
        'priority_score': priority['scores'][0]
    }
```

### ğŸ“° **Haber Agregasyon Sistemi**
```python
# Haber makalelerini Ã¶zetle ve sÄ±nÄ±flandÄ±r
def process_news_article(article):
    # Ã–zetleme
    summarizer = pipeline("summarization")
    summary = summarizer(article, max_length=100, min_length=30)[0]['summary_text']
    
    # Kategori
    classifier = pipeline("zero-shot-classification")
    categories = ["politics", "technology", "sports", "health", "business"]
    category = classifier(summary, categories)
    
    # Anahtar varlÄ±klar
    ner = pipeline("ner", grouped_entities=True)
    entities = ner(summary)
    
    return {
        'summary': summary,
        'category': category['labels'][0],
        'confidence': category['scores'][0],
        'entities': [e['word'] for e in entities]
    }
```

---

## ğŸ“š Kaynaklar ve Referanslar

### ğŸ“ **Akademik Makaleler**
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) - Original Transformer (Vaswani et al., 2017)
- [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805) - BERT (Devlin et al., 2018)
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) - GPT-3 (Brown et al., 2020)
- [BART: Denoising Sequence-to-Sequence Pre-training](https://arxiv.org/abs/1910.13461) - BART (Lewis et al., 2019)
- [Exploring the Limits of Transfer Learning with T5](https://arxiv.org/abs/1910.10683) - T5 (Raffel et al., 2019)

### ğŸ› ï¸ **Teknik DokÃ¼mantasyon**
- [Hugging Face Transformers Docs](https://huggingface.co/docs/transformers/)
- [Hugging Face Model Hub](https://huggingface.co/models)
- [OpenAI API Documentation](https://platform.openai.com/docs/)
- [PyTorch Documentation](https://pytorch.org/docs/)
- [Sumy Documentation](https://github.com/miso-belica/sumy)

### ğŸ“– **Ã–ÄŸrenme KaynaklarÄ±**
- [Hugging Face Course](https://huggingface.co/course) - Ãœcretsiz NLP kursu
- [Fast.ai NLP Course](https://www.fast.ai/) - Pratik odaklÄ±
- [Stanford CS224N](http://web.stanford.edu/class/cs224n/) - NLP with Deep Learning
- [Jay Alammar's Blog](https://jalammar.github.io/) - GÃ¶rsel transformers aÃ§Ä±klamalarÄ±

### ğŸ¯ **Veri Setleri**
- [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) - Question Answering
- [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) - Summarization
- [SST-2](https://huggingface.co/datasets/sst2) - Sentiment Analysis
- [CoNLL-2003](https://huggingface.co/datasets/conll2003) - Named Entity Recognition

---

## ğŸ¯ SonuÃ§lar ve Ã–neriler

### âœ… **Ã–nemli Ã‡Ä±karÄ±mlar:**
1. **Pipeline API GÃ¼cÃ¼:** Transformers Pipeline API, kompleks NLP gÃ¶revlerini 2-3 satÄ±rda Ã§Ã¶zmeyi saÄŸlar
2. **Model Ã‡eÅŸitliliÄŸi:** Her gÃ¶rev iÃ§in optimize edilmiÅŸ onlarca model mevcut (hÄ±z, doÄŸruluk, dil desteÄŸi)
3. **Transfer Learning:** Pre-trained modeller sayesinde az veriyle yÃ¼ksek performans elde edilir
4. **Ekstraktif vs Abstraktif:** FaktÃ¼el gÃ¶revlerde ekstraktif, yaratÄ±cÄ± gÃ¶revlerde abstraktif modeller Ã¼stÃ¼n
5. **API Entegrasyonu:** OpenAI API ile production-ready chatbot hÄ±zlÄ±ca geliÅŸtirilebilir

### ğŸ”¥ **Profesyonel Ä°puÃ§larÄ±:**
- **Model Caching:** Modelleri disk'e kaydedin, tekrar indirmeyin (`save_pretrained()`)
- **Batch Processing:** Tek tek yerine batch olarak iÅŸleyerek 5-10x hÄ±zlanma saÄŸlayÄ±n
- **GPU KullanÄ±mÄ±:** BÃ¼yÃ¼k modellerde GPU kullanÄ±mÄ± zorunludur (CUDA device)
- **Quantization:** INT8 quantization ile model boyutunu %75 azaltÄ±n
- **Error Handling:** API Ã§aÄŸrÄ±larÄ±nda retry mekanizmasÄ± ve rate limiting uygulayÄ±n
- **Prompt Engineering:** Zero-shot ve chatbot'larda prompt kalitesi kritiktir

### ğŸŒŸ **Gelecek AdÄ±mlar:**
1. **Fine-tuning:** Kendi veri setinizde modelleri fine-tune edin
2. **Multi-lingual:** XLM-RoBERTa ile Ã§ok dilli uygulamalar geliÅŸtirin
3. **RAG Systems:** Retrieval-Augmented Generation ile QA sistemlerini geliÅŸtirin
4. **LangChain:** LLM uygulamalarÄ± iÃ§in framework kullanÄ±n
5. **Vector Databases:** Pinecone, Weaviate ile semantic search ekleyin

---

> **"Transformer modelleri NLP'de paradigma deÄŸiÅŸimi yarattÄ±. ArtÄ±k state-of-the-art performans birkaÃ§ satÄ±r kod ile eriÅŸilebilir durumda. BaÅŸarÄ±, doÄŸru model seÃ§imi, parametre ayarlama ve verimli pipeline yÃ¶netiminde yatar!"** 

---

<p align="center">
  <sub>ğŸ“§ SorularÄ±nÄ±z iÃ§in: <a href="mailto:cyuksel@bandirma.edu.tr">iletiÅŸime geÃ§in</a> | ğŸŒŸ Hugging Face: <a href="https://huggingface.co/">huggingface.co</a> | ğŸ¤– OpenAI: <a href="https://platform.openai.com/">platform.openai.com</a></sub>
</p>
