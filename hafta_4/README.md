## ğŸ¯ GeliÅŸmiÅŸ NLP UygulamalarÄ± YolculuÄŸu

<p align="center">
  <b>Metin sÄ±nÄ±flandÄ±rma ve duygu analizi ile gerÃ§ek dÃ¼nya problemlerini Ã§Ã¶zmek iÃ§in profesyonel NLP teknikleri!</b>
</p>

```mermaid
flowchart TD
    style A1 fill:#E8F6F3,stroke:#1B8E6B,stroke-width:2px
    style B1 fill:#FEF9E7,stroke:#D68910,stroke-width:2px
    style B2 fill:#EBF5FB,stroke:#2874A6,stroke-width:2px
    style B3 fill:#FADBD8,stroke:#C0392B,stroke-width:2px
    style B4 fill:#E8DAEF,stroke:#8E44AD,stroke-width:2px
    style B5 fill:#D6EAF8,stroke:#2980B9,stroke-width:2px
    style B6 fill:#FDEBD0,stroke:#CA6F1E,stroke-width:2px
    style B7 fill:#F0F3FF,stroke:#4A69BD,stroke-width:2px
    style B8 fill:#E8F8F5,stroke:#17A2B8,stroke-width:2px
    style B9 fill:#FFF2CC,stroke:#F39C12,stroke-width:2px
    style B10 fill:#E1F5FE,stroke:#0277BD,stroke-width:2px
    style Z1 fill:#F8F9FA,stroke:#6C757D,stroke-width:2px

    A1([ğŸ”¤ Ham Metin Verisi])
    B1([ğŸ“¥ Veri YÃ¼kleme<br><i>Tweet & Duygu Verileri</i>])
    B2([ğŸ§¹ Ã–n Ä°ÅŸleme<br><i>Tokenization, Temizlik</i>])
    B3([ğŸ“Š KeÅŸifsel Analiz<br><i>Veri DaÄŸÄ±lÄ±mÄ± & Ä°statistikler</i>])
    B4([ğŸ”¤ Ã–zellik Ã‡Ä±karÄ±mÄ±<br><i>TF-IDF, Word Embeddings</i>])
    B5([ğŸ¤– Klasik ML<br><i>Naive Bayes, SVM</i>])
    B6([ğŸ§  Derin Ã–ÄŸrenme<br><i>Neural Networks, LSTM</i>])
    B7([ğŸ”¥ Transformer Modelleri<br><i>BERT, RoBERTa</i>])
    B8([ğŸ“ˆ Model DeÄŸerlendirme<br><i>Accuracy, F1, Confusion Matrix</i>])
    B9([ğŸ’­ Duygu Analizi<br><i>VADER, BERT Sentiment</i>])
    B10([ğŸ¨ GÃ¶rselleÅŸtirme<br><i>SonuÃ§ Analizi</i>])
    Z1([ğŸ¯ Ãœretim HazÄ±r Model])

    A1 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> B4
    B4 --> B5
    B5 --> B6
    B6 --> B7
    B7 --> B8
    B2 --> B9
    B9 --> B10
    B8 --> B10
    B10 --> Z1

    B3 -.-> B5
    B4 -.-> B9
    B6 -.-> B8
    B7 -.-> B10
```

---

## ğŸ“Š Proje Ã–zeti

Bu klasÃ¶rde, **Twitter felaket tespiti** ve **duygu analizi** olmak Ã¼zere iki kritik NLP problemi Ã¼zerinde Ã§alÄ±ÅŸÄ±lmaktadÄ±r. 
Projeler, gerÃ§ek dÃ¼nya verisiyle, endÃ¼stri standardÄ± Python kÃ¼tÃ¼phaneleri (pandas, scikit-learn, transformers, tensorflow) ve gÃ¼ncel makine Ã¶ÄŸrenmesi yaklaÅŸÄ±mlarÄ±yla geliÅŸtirilmiÅŸtir.

### Ana Konular:
- **Metin SÄ±nÄ±flandÄ±rma**: Tweet'lerin felaket iÃ§erip iÃ§ermediÄŸini belirleme
- **Duygu Analizi**: Metinlerdeki duygusal tonun otomatik tespiti
- **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±**: Klasik ML vs Derin Ã–ÄŸrenme vs Transformers
- **Pratik Uygulamalar**: VADER, BERT ve Ã¶zel modeller

---

## ğŸŒŸ DetaylÄ± Ã‡alÄ±ÅŸma AÅŸamalarÄ± & Flashcardlar

### 1. **ğŸ“¥ Veri YÃ¼kleme ve Ä°nceleme**
- **AmaÃ§:** Tweet felaket veri seti ve duygu analizi verilerinin sistem iÃ§ine alÄ±nmasÄ±.
- <div style="border:1px solid #1B8E6B; border-radius:8px; padding:12px; background:#E8F6F3; margin:10px 0;">
  <b>Soru:</b> Neden veri kalitesi kontrol edilmelidir ve hangi faktÃ¶rler dikkate alÄ±nmalÄ±dÄ±r?<br>
  <b>Cevap:</b> Eksik veriler, duplikatlar ve etiket dengesizlikleri model performansÄ±nÄ± doÄŸrudan etkilediÄŸi iÃ§in veri kalitesi kritiktir.
  </div>

---

### 2. **ğŸ§¹ Metin Ã–n Ä°ÅŸleme (Text Preprocessing)**
- **AÅŸamalar:**  
  - KÃ¼Ã§Ã¼k harfe Ã§evirme, noktalama temizliÄŸi, URL/mention kaldÄ±rma
  - Tokenization ve stop words elimination
- **Kod:**
  ```python
  import re
  import nltk
  from nltk.corpus import stopwords
  
  def metin_temizle(text):
      # URL'leri kaldÄ±r
      text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
      # Mention ve hashtag'leri kaldÄ±r  
      text = re.sub(r'@\w+|#\w+', '', text)
      # Sadece harfleri bÄ±rak
      text = re.sub(r'[^a-zA-ZÃ§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄÄ°Ã–ÅÃœ\s]', '', text)
      return text.lower().strip()
  
  # Ã–rnek kullanÄ±m
  ornek_tweet = "@user Bu #deprem gerÃ§ekten korkunÃ§! https://example.com"
  temiz_tweet = metin_temizle(ornek_tweet)
  print(temiz_tweet)  # output: "bu deprem gerÃ§ekten korkunÃ§"
  ```
- <div style="border:1px solid #2874A6; border-radius:8px; padding:12px; background:#EBF5FB; margin:10px 0;">
  <b>Soru:</b> Metin Ã¶n iÅŸleme adÄ±mlarÄ± neden kritiktir ve hangi problemleri Ã§Ã¶zer?<br>
  <b>Cevap:</b> GÃ¼rÃ¼ltÃ¼lÃ¼ karakterleri kaldÄ±rarak veriyi standardize eder, model iÃ§in anlamlÄ± Ã¶zellikler Ã§Ä±karmayÄ± kolaylaÅŸtÄ±rÄ±r.
  </div>

---

### 3. **ğŸ“Š KeÅŸifsel Veri Analizi (EDA)**
- **AmaÃ§:** Veri setinin yapÄ±sÄ±nÄ±, daÄŸÄ±lÄ±mÄ±nÄ± ve Ã¶zelliklerini anlamak.
- **Visualizasyonlar:** Kelime bulutu, etiket daÄŸÄ±lÄ±mÄ±, metin uzunluk analizi
- <div style="border:1px solid #C0392B; border-radius:8px; padding:12px; background:#FADBD8; margin:10px 0;">
  <b>Soru:</b> EDA'nÄ±n model seÃ§imi ve hiperparametre ayarlamada rolÃ¼ nedir?<br>
  <b>Cevap:</b> Veri dengesizlikleri, aykÄ±rÄ± deÄŸerler ve Ã¶zellik daÄŸÄ±lÄ±mlarÄ± hakkÄ±nda bilgi vererek doÄŸru model mimarisi seÃ§imini saÄŸlar.
  </div>

---

### 4. **ğŸ”¤ Ã–zellik Ã‡Ä±karÄ±mÄ± (Feature Extraction)**
- **Teknikler:**  
  - TF-IDF Vectorization
  - Word Embeddings (Word2Vec, GloVe)
  - Neural Text Vectorization
- **Kod:**
  ```python
  from sklearn.feature_extraction.text import TfidfVectorizer
  import tensorflow as tf
  
  # TF-IDF YaklaÅŸÄ±mÄ±
  tfidf = TfidfVectorizer(max_features=10000, ngram_range=(1,2))
  X_tfidf = tfidf.fit_transform(temiz_metinler)
  
  # Neural Text Vectorization
  text_vectorizer = tf.keras.layers.TextVectorization(
      max_tokens=10000,
      output_sequence_length=100
  )
  text_vectorizer.adapt(temiz_metinler)
  X_neural = text_vectorizer(temiz_metinler)
  ```
- <div style="border:1px solid #8E44AD; border-radius:8px; padding:12px; background:#E8DAEF; margin:10px 0;">
  <b>Soru:</b> TF-IDF ve neural embeddings arasÄ±ndaki temel farklar nelerdir?<br>
  <b>Cevap:</b> TF-IDF sparse vektÃ¶rler Ã¼retir ve kelime sÄ±klÄ±ÄŸÄ±na odaklanÄ±r; neural embeddings dense vektÃ¶rler ile semantik iliÅŸkileri yakalar.
  </div>

---

### 5. **ğŸ¤– Klasik Makine Ã–ÄŸrenmesi**
- **Algoritmalar:**  
  - Naive Bayes (Multinomial)
  - Support Vector Machine (SVM)
  - Logistic Regression
- **Kod:**
  ```python
  from sklearn.naive_bayes import MultinomialNB
  from sklearn.pipeline import Pipeline
  from sklearn.metrics import classification_report
  
  # Pipeline oluÅŸturma
  klasik_model = Pipeline([
      ('tfidf', TfidfVectorizer(max_features=10000)),
      ('classifier', MultinomialNB())
  ])
  
  # EÄŸitim ve deÄŸerlendirme
  klasik_model.fit(X_train, y_train)
  y_pred = klasik_model.predict(X_test)
  print(classification_report(y_test, y_pred))
  ```
- <div style="border:1px solid #2980B9; border-radius:8px; padding:12px; background:#D6EAF8; margin:10px 0;">
  <b>Soru:</b> Klasik ML algoritmalarÄ±nÄ±n NLP'deki avantaj ve dezavantajlarÄ± nelerdir?<br>
  <b>Cevap:</b> HÄ±zlÄ±, aÃ§Ä±klanabilir ve az veri ile Ã§alÄ±ÅŸabilir; ancak karmaÅŸÄ±k dil Ã¶rÃ¼ntÃ¼lerini yakalamada sÄ±nÄ±rlÄ±dÄ±r.
  </div>

---

### 6. **ğŸ§  Derin Ã–ÄŸrenme Modelleri**
- **Mimariler:**  
  - Dense Neural Networks
  - LSTM/GRU Networks
  - CNN for Text
- **Kod:**
  ```python
  import tensorflow as tf
  from tensorflow.keras.models import Sequential
  from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
  
  # LSTM Model
  model = Sequential([
      Embedding(vocab_size, 128, input_length=max_length),
      LSTM(64, dropout=0.5, recurrent_dropout=0.5),
      Dense(32, activation='relu'),
      Dropout(0.5),
      Dense(1, activation='sigmoid')
  ])
  
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
  history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)
  ```
- <div style="border:1px solid #CA6F1E; border-radius:8px; padding:12px; background:#FDEBD0; margin:10px 0;">
  <b>Soru:</b> LSTM'in metin sÄ±nÄ±flandÄ±rmada neden etkili olduÄŸu ve hangi problemleri Ã§Ã¶zdÃ¼ÄŸÃ¼ nedir?<br>
  <b>Cevap:</b> Uzun menzilli baÄŸÄ±mlÄ±lÄ±klarÄ± yakalayarak kelime sÄ±rasÄ± ve baÄŸlamsal iliÅŸkileri Ã¶ÄŸrenir.
  </div>

---

### 7. **ğŸ”¥ Transformer TabanlÄ± Modeller**
- **Modern YaklaÅŸÄ±mlar:**  
  - BERT (Bidirectional Encoder Representations)
  - RoBERTa (Robustly Optimized BERT)
  - DistilBERT (Lightweight BERT)
- **Kod:**
  ```python
  from transformers import AutoTokenizer, AutoModelForSequenceClassification
  from transformers import TrainingArguments, Trainer
  
  # BERT Model yÃ¼kleme
  model_name = "dbmdz/bert-base-turkish-cased"
  tokenizer = AutoTokenizer.from_pretrained(model_name)
  model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
  
  # Tokenization
  def tokenize_texts(texts):
      return tokenizer(texts, truncation=True, padding=True, return_tensors="pt")
  
  # Fine-tuning iÃ§in training setup
  training_args = TrainingArguments(
      output_dir='./results',
      num_train_epochs=3,
      per_device_train_batch_size=16,
      per_device_eval_batch_size=64,
      warmup_steps=500,
      weight_decay=0.01,
  )
  ```
- <div style="border:1px solid #4A69BD; border-radius:8px; padding:12px; background:#F0F3FF; margin:10px 0;">
  <b>Soru:</b> Transformer modellerinin geleneksel yaklaÅŸÄ±mlara gÃ¶re Ã¼stÃ¼nlÃ¼kleri nelerdir?<br>
  <b>Cevap:</b> Attention mechanism ile global baÄŸlamÄ± anlayabilir, transfer learning ile az veriyle yÃ¼ksek performans saÄŸlar.
  </div>

---

### 8. **ğŸ’­ Duygu Analizi UygulamalarÄ±**
- **YaklaÅŸÄ±mlar:**  
  - VADER Sentiment Analyzer (Kural tabanlÄ±)
  - TextBlob (Basit ML)
  - BERT-based Sentiment (SOTA)
- **Kod:**
  ```python
  from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
  from transformers import pipeline
  
  # VADER Analyzer
  vader = SentimentIntensityAnalyzer()
  
  def vader_analiz(text):
      scores = vader.polarity_scores(text)
      return scores['compound']  # -1 (negatif) ile +1 (pozitif) arasÄ±
  
  # BERT Sentiment Pipeline
  sentiment_pipeline = pipeline("sentiment-analysis", 
                               model="nlptown/bert-base-multilingual-uncased-sentiment")
  
  # Ã–rnek kullanÄ±m
  ornek_metin = "Bu Ã¼rÃ¼n gerÃ§ekten harika, Ã§ok memnun kaldÄ±m!"
  vader_skor = vader_analiz(ornek_metin)
  bert_sonuc = sentiment_pipeline(ornek_metin)
  
  print(f"VADER Skoru: {vader_skor}")
  print(f"BERT Sonucu: {bert_sonuc}")
  ```
- <div style="border:1px solid #17A2B8; border-radius:8px; padding:12px; background:#E8F8F5; margin:10px 0;">
  <b>Soru:</b> VADER ve BERT tabanlÄ± duygu analizi arasÄ±ndaki temel farklar nelerdir?<br>
  <b>Cevap:</b> VADER hÄ±zlÄ± ve kurallara dayalÄ±; BERT baÄŸlamÄ± anlayarak daha doÄŸru ama hesaplama aÃ§Ä±sÄ±ndan aÄŸÄ±r.
  </div>

---

### 9. **ğŸ“ˆ Model DeÄŸerlendirme ve KarÅŸÄ±laÅŸtÄ±rma**
- **Metrikler:**  
  - Accuracy, Precision, Recall, F1-Score
  - ROC-AUC, Confusion Matrix
  - Cross-validation
- **Kod:**
  ```python
  from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
  import matplotlib.pyplot as plt
  import seaborn as sns
  
  def model_degerlendirme(y_true, y_pred, y_proba=None):
      # Temel metrikler
      print("Classification Report:")
      print(classification_report(y_true, y_pred))
      
      # Confusion Matrix
      cm = confusion_matrix(y_true, y_pred)
      plt.figure(figsize=(8, 6))
      sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
      plt.title('Confusion Matrix')
      plt.ylabel('GerÃ§ek Etiket')
      plt.xlabel('Tahmin Edilen Etiket')
      plt.show()
      
      # ROC-AUC (ikili sÄ±nÄ±flandÄ±rma iÃ§in)
      if y_proba is not None:
          auc = roc_auc_score(y_true, y_proba)
          print(f"ROC-AUC Score: {auc:.4f}")
  
  # Model karÅŸÄ±laÅŸtÄ±rmasÄ±
  model_sonuclari = {
      'Naive Bayes': {'accuracy': 0.82, 'f1': 0.79, 'training_time': 2.1},
      'LSTM': {'accuracy': 0.87, 'f1': 0.85, 'training_time': 45.2},
      'BERT': {'accuracy': 0.93, 'f1': 0.91, 'training_time': 180.5}
  }
  ```
- <div style="border:1px solid #F39C12; border-radius:8px; padding:12px; background:#FFF2CC; margin:10px 0;">
  <b>Soru:</b> Model seÃ§iminde accuracy dÄ±ÅŸÄ±nda hangi faktÃ¶rler dikkate alÄ±nmalÄ±dÄ±r?<br>
  <b>Cevap:</b> F1-score (dengesiz veri iÃ§in), eÄŸitim sÃ¼resi, Ã§Ä±karÄ±m hÄ±zÄ±, model boyutu ve aÃ§Ä±klanabilirlik.
  </div>

---

### 10. **ğŸ¨ SonuÃ§larÄ±n GÃ¶rselleÅŸtirilmesi**
- **AmaÃ§:** Model performanslarÄ±nÄ±n ve sonuÃ§larÄ±n anlaÅŸÄ±lÄ±r ÅŸekilde sunulmasÄ±.
- **Teknikler:** ROC eÄŸrileri, Ã¶zellik Ã¶nem analizi, t-SNE gÃ¶rselleÅŸtirme
- <div style="border:1px solid #0277BD; border-radius:8px; padding:12px; background:#E1F5FE; margin:10px 0;">
  <b>Soru:</b> GÃ¶rselleÅŸtirmenin model geliÅŸtirme sÃ¼recindeki rolÃ¼ nedir?<br>
  <b>Cevap:</b> Model davranÄ±ÅŸÄ±nÄ± anlamak, hatalarÄ± tespit etmek ve sonuÃ§larÄ± stakeholder'lara etkili ÅŸekilde sunmak iÃ§in kritiktir.
  </div>

---

## ğŸ“‚ KlasÃ¶r Ä°Ã§eriÄŸi

- `01-text-classification.ipynb` : Tweet felaket sÄ±nÄ±flandÄ±rma projesi (kapsamlÄ± NLP rehberi)
- `02-sentimentanalysis.ipynb` : Duygu analizi uygulamalarÄ± (VADER + BERT)
- `train.csv` : Twitter felaket veri seti (eÄŸitim)
- `test.csv` : Twitter felaket veri seti (test)

---

## ğŸ”§ Teknik Gereksinimler

```python
# Temel kÃ¼tÃ¼phaneler
pandas >= 1.3.0
numpy >= 1.21.0
matplotlib >= 3.4.0
seaborn >= 0.11.0

# Machine Learning
scikit-learn >= 1.0.0
tensorflow >= 2.8.0

# NLP KÃ¼tÃ¼phaneleri
transformers >= 4.15.0
vaderSentiment >= 3.3.2
nltk >= 3.7

# GÃ¶rselleÅŸtirme
wordcloud >= 1.8.2
plotly >= 5.0.0
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

1. **Ortam HazÄ±rlÄ±ÄŸÄ±:**
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn tensorflow transformers vaderSentiment nltk
   ```

2. **Veri Ä°ndirme:**
   ```python
   import nltk
   nltk.download('stopwords')
   nltk.download('punkt')
   ```

3. **Ä°lk Model:**
   ```python
   # Basit metin sÄ±nÄ±flandÄ±rma
   from sklearn.feature_extraction.text import TfidfVectorizer
   from sklearn.naive_bayes import MultinomialNB
   from sklearn.pipeline import Pipeline
   
   model = Pipeline([
       ('tfidf', TfidfVectorizer()),
       ('classifier', MultinomialNB())
   ])
   ```

---

## ğŸ“Š Beklenen SonuÃ§lar

| Model | Accuracy | F1-Score | EÄŸitim SÃ¼resi | Ã‡Ä±karÄ±m HÄ±zÄ± |
|-------|----------|----------|---------------|---------------|
| Naive Bayes + TF-IDF | ~82% | ~79% | 2-3 saniye | Ã‡ok HÄ±zlÄ± |
| LSTM + Embeddings | ~87% | ~85% | 5-10 dakika | Orta |
| BERT Fine-tuned | ~93% | ~91% | 30-60 dakika | YavaÅŸ |

---

## ğŸ’¡ Kaynaklar ve Referanslar

### ğŸ“š Akademik Kaynaklar
- [BERT Paper](https://arxiv.org/abs/1810.04805) - Bidirectional Encoder Representations
- [VADER Paper](http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf) - Sentiment Analysis Tool

### ğŸ› ï¸ Teknik DokÃ¼mantasyonlar
- [Transformers Library](https://huggingface.co/docs/transformers/index)
- [TensorFlow Text](https://www.tensorflow.org/text)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)

### ğŸ¯ Pratik Uygulamalar
- [Kaggle Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)
- [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/)
- [TÃ¼rkÃ§e NLP KaynaklarÄ±](https://github.com/ahmetax/tr-nlp-tools)

---

## ğŸ¯ SonuÃ§lar ve Ã–neriler

### âœ… **Ã–nemli Ã‡Ä±karÄ±mlar:**
1. **HÄ±z vs DoÄŸruluk:** Klasik ML hÄ±zlÄ± prototipleme iÃ§in, Transformers Ã¼retim kalitesi iÃ§in
2. **Veri Boyutu:** Az veri (<1000 Ã¶rnek) iÃ§in TF-IDF, bÃ¼yÃ¼k veri iÃ§in deep learning
3. **TÃ¼rkÃ§e Destek:** BERT-tÃ¼rkÃ§e modelleri Ä°ngilizce'den daha iyi performans gÃ¶steriyor
4. **Ensemble YaklaÅŸÄ±mÄ±:** VADER + BERT kombinasyonu robust sonuÃ§lar veriyor

### ğŸ”¥ **Best Practices:**
- Her zaman veri kalitesini kontrol edin (duplikatlar, eksik etiketler)
- Cross-validation ile overfitting'i Ã¶nleyin
- Model aÃ§Ä±klanabilirliÄŸini unutmayÄ±n
- A/B testing ile gerÃ§ek performansÄ± Ã¶lÃ§Ã¼n

---

> **"NLP'de tek doÄŸru yaklaÅŸÄ±m yoktur. Problem, veri ve kaynaklarÄ±nÄ±za gÃ¶re en uygun tekniÄŸi seÃ§in. BaÅŸarÄ±, algoritmanÄ±n gÃ¼cÃ¼nden Ã§ok veri kalitesi ve doÄŸru yaklaÅŸÄ±m seÃ§iminde yatar!"** 

---

<p align="center">
  <sub>ğŸ“§ SorularÄ±nÄ±z iÃ§in: <a href="mailto:cyuksel@bandirma.edu.tr">iletiÅŸime geÃ§in</a> | ğŸŒŸ Bu projeyi beÄŸendiyseniz star vermeyi unutmayÄ±n!</sub>
</p>