<div align="center">

# ğŸš€ Hafta 2: Metin Temsilleri ve Word Embeddings

**Kairu NLP Bootcamp | ModÃ¼l 2**

</div>

> **Misyon:** Bu modÃ¼l, metin verisinin ham karakter dizilerinden, makine Ã¶ÄŸrenmesi algoritmalarÄ± iÃ§in anlamlÄ± sayÄ±sal formatlara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lme sÃ¼recini derinlemesine inceler. Klasik frekans tabanlÄ± **seyrek (sparse) vektÃ¶r** modellerinden, kelimelerin anlamsal ve sÃ¶zdizimsel iliÅŸkilerini yÃ¼ksek boyutlu bir uzayda yakalayan **yoÄŸun (dense) vektÃ¶r** yani **Word Embedding** paradigmalarÄ±na geÃ§iÅŸ yapÄ±lacaktÄ±r.

---

### ğŸ¯ HaftanÄ±n Hedefleri

Bu modÃ¼lÃ¼n sonunda aÅŸaÄŸÄ±daki yetkinliklerin kazanÄ±lmasÄ± hedeflenmektedir:

-   âœ… **Seyrek ve YoÄŸun Temsillerin AyrÄ±mÄ±nÄ± Yapma:** Ä°ki yaklaÅŸÄ±mÄ±n matematiksel temellerini, avantajlarÄ±nÄ± ve dezavantajlarÄ±nÄ± anlama.
-   âœ… **Frekans TabanlÄ± Modelleri Implemente Etme:** **Bag-of-Words (BoW)** ve **TF-IDF** vektÃ¶rleÅŸtiricilerini `scikit-learn` ile uygulayabilme ve sonuÃ§larÄ±nÄ± yorumlayabilme.
-   âœ… **Word Embedding MantÄ±ÄŸÄ±nÄ± Kavrama:** **DaÄŸÄ±tÄ±msal Hipotez** temelinde **Word2Vec (CBOW & Skip-gram)** ve **GloVe** gibi modellerin sezgisel ve mimari altyapÄ±sÄ±nÄ± aÃ§Ä±klayabilme.
-   âœ… **Ã–zelleÅŸtirilmiÅŸ Model EÄŸitme:** `gensim` kÃ¼tÃ¼phanesini kullanarak, verilen bir TÃ¼rkÃ§e metin korpusu (`hurriyet.txt`) Ã¼zerinden sÄ±fÄ±rdan bir Word2Vec modeli eÄŸitme.
-   âœ… **Transfer Learning Uygulama:** Ã–nceden eÄŸitilmiÅŸ, endÃ¼stri standardÄ± **GloVe** kelime vektÃ¶rlerini projelere dahil etme ve anlamsal analizler iÃ§in kullanma.
-   âœ… **UÃ§tan Uca Proje GeliÅŸtirme:** FarklÄ± metin temsil yÃ¶ntemlerini, duygu analizi gibi bir sÄ±nÄ±flandÄ±rma probleminde karÅŸÄ±laÅŸtÄ±rmalÄ± olarak test etme.

---

### ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ±

Bu hafta kullanÄ±lan temel araÃ§lar ve kÃ¼tÃ¼phaneler:

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![Gensim](https://img.shields.io/badge/Gensim-4.3+-brightgreen?style=for-the-badge)](https://radimrehurek.com/gensim/)
[![Scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-%23F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/)
[![Pandas](https://img.shields.io/badge/Pandas-1.5+-150458?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org/)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.7+-white?style=for-the-badge&logo=matplotlib&logoColor=black)](https://matplotlib.org/)

</div>

---

### ğŸ“‚ HaftanÄ±n Ä°Ã§erikleri ve Stratejik Rolleri

ModÃ¼l boyunca kullanÄ±lacak tÃ¼m materyaller ve veri setleri aÅŸaÄŸÄ±da aÃ§Ä±klanmÄ±ÅŸtÄ±r.

| Dosya TÃ¼rÃ¼ | Dosya AdÄ± | AÃ§Ä±klama ve Stratejik RolÃ¼ |
| :--- | :--- | :--- |
| ğŸ§  **Jupyter Notebook** | `01.Text Representations.ipynb` | **Teorik Temeller:** BoW ve TF-IDF'in matematiksel altyapÄ±sÄ±nÄ± ve pratik implementasyonlarÄ±nÄ± iÃ§eren baÅŸlangÄ±Ã§ noktasÄ±. |
| ğŸ’» **Jupyter Notebook** | `02-Word2vec and GloVe.ipynb` | **Derinlemesine Uygulama:** `gensim` ile Ã¶zel model eÄŸitimi ve Ã¶nceden eÄŸitilmiÅŸ GloVe vektÃ¶rlerinin analizi. |
| ğŸ§ª **Jupyter Notebook** | `03 - Case 2 Solution.ipynb` | **Sentez ve Analiz:** HaftanÄ±n konularÄ±nÄ± birleÅŸtiren ve farklÄ± temsil stratejilerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran vaka analizi. |
| ğŸ’¾ **Veri Seti** | `IMDB Dataset.csv` | Vaka Ã§alÄ±ÅŸmasÄ±nÄ±n temelini oluÅŸturan, pozitif/negatif film yorumlarÄ±nÄ± iÃ§eren zengin veri seti. |
| ğŸ“„ **Korpus** | `hurriyet.txt` | TÃ¼rkÃ§e NLP yeteneklerini test etmek ve sÄ±fÄ±rdan bir model eÄŸitmek iÃ§in kullanÄ±lacak yerel metin korpusu. |
| ğŸŒ **Pre-trained Model** | `glove.6B.100d.txt` | Milyarlarca kelime Ã¼zerinde eÄŸitilmiÅŸ, `transfer learning` iÃ§in kullanÄ±lacak endÃ¼stri standardÄ± GloVe vektÃ¶rleri. |

---

### ğŸ”¬ Teknik GÃ¼ndem: Seyrek ve YoÄŸun VektÃ¶r UzaylarÄ±

| Alan | Ä°ÅŸlenen Modeller ve Teknikler | Temel Kavramlar |
| :--- | :--- | :--- |
| **Seyrek Temsiller** | â€¢ Bag of Words (BoW)<br/>â€¢ TF-IDF VektÃ¶rleÅŸtirme<br/>â€¢ N-Gram Modellemesi | `Sparsity`, `Term Frequency`, `Inverse Document Frequency`, `Vocabulary`, `Document-Term Matrix` |
| **YoÄŸun Temsiller** | â€¢ Word2Vec Mimarisi<br/>â€¢ GloVe Mimarisi<br/>â€¢ Ã–nceden EÄŸitilmiÅŸ Modeller | `Dense Vectors`, `Distributional Hypothesis`, `CBOW`, `Skip-gram`, `Co-occurrence Matrix`, `Semantic Similarity` |

---

###  casework Vaka Analizleri

Bu hafta iki temel uygulamalÄ± Ã§alÄ±ÅŸma gerÃ§ekleÅŸtirilmiÅŸtir:

1.  **Sentiment Analysis (Ä°ngilizce):**
    -   **Veri Seti:** `IMDB Dataset.csv`
    -   **AmaÃ§:** BoW, TF-IDF ve GloVe vektÃ¶rlerini kullanarak bir metnin duygu (pozitif/negatif) durumunu tahmin eden modeller geliÅŸtirmek ve bu Ã¼Ã§ temsil yÃ¶nteminin model doÄŸruluÄŸuna etkisini karÅŸÄ±laÅŸtÄ±rmak. Bu Ã§alÄ±ÅŸma `03 - Case 2 Solution.ipynb` iÃ§inde detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.

2.  **Custom Word2Vec Model Training (TÃ¼rkÃ§e):**
    -   **Veri Seti:** `hurriyet.txt`
    -   **AmaÃ§:** TÃ¼rkÃ§e bir metin korpusu Ã¼zerinde sÄ±fÄ±rdan bir Word2Vec modeli eÄŸitmek. EÄŸitilen model ile kelimeler arasÄ±ndaki anlamsal benzerlikleri (`"ankara"` kelimesine en yakÄ±n kelimeler) ve analojileri keÅŸfetmek. Bu Ã§alÄ±ÅŸma `02-Word2vec and GloVe.ipynb` iÃ§inde yer almaktadÄ±r.

---

### âœ… KazanÄ±lan Yetkinlikler ve Somut Ã‡Ä±ktÄ±lar

-   **VektÃ¶rleÅŸtirme:** Ham metin verisini, makine Ã¶ÄŸrenmesi modellerinin anlayabileceÄŸi BoW ve TF-IDF matrislerine baÅŸarÄ±lÄ± bir ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rme.
-   **Model EÄŸitimi:** `gensim` kÃ¼tÃ¼phanesini kullanarak Ã¶zel bir korpus ile tamamen iÅŸlevsel bir Word2Vec modeli eÄŸitme ve kaydetme.
-   **Anlamsal Analiz:** Ã–nceden eÄŸitilmiÅŸ GloVe vektÃ¶rlerini kullanarak kelime analojilerini (`kral - erkek + kadÄ±n = kraliÃ§e`) test etme ve kelimeler arasÄ± kosinÃ¼s benzerliÄŸini hesaplama.
-   **KarÅŸÄ±laÅŸtÄ±rmalÄ± Rapor:** FarklÄ± metin temsil yÃ¶ntemlerinin, duygu analizi performansÄ± Ã¼zerindeki etkisini (doÄŸruluk, F1 skoru vb.) gÃ¶steren bir analiz raporu oluÅŸturma.

---

> ğŸ“Œ **Sonraki AdÄ±mlar:** Bu hafta Ã¶ÄŸrendiÄŸimiz yoÄŸun vektÃ¶r temsilleri (word embeddings), kelimelerin sabit anlamlarÄ±ndan ziyade baÄŸlama gÃ¶re deÄŸiÅŸen anlamlarÄ±nÄ± yakalayabilen, bir sonraki modÃ¼lÃ¼mÃ¼zÃ¼n konusu olan **Transformer tabanlÄ± modern NLP modelleri (BERT, GPT)** iÃ§in kritik bir altyapÄ± ve geÃ§iÅŸ noktasÄ± saÄŸlamaktadÄ±r.v
