# ğŸš€ Hafta 2 â€“ Metin Temsilleri ve Word Embeddings

Bu klasÃ¶r, **Kairu NLP Bootcamp** programÄ±nÄ±n ikinci haftasÄ±na ait ders notlarÄ±nÄ±, uygulamalÄ± Ã§alÄ±ÅŸmalarÄ± ve veri setlerini iÃ§erir. AmaÃ§, katÄ±lÄ±mcÄ±lara metin verisini makine Ã¶ÄŸrenmesi modelleri iÃ§in anlamlÄ± sayÄ±sal temsillere dÃ¶nÃ¼ÅŸtÃ¼rme yetkinliÄŸi kazandÄ±rmaktÄ±r. Bu hafta, klasik **seyrek (sparse) vektÃ¶r** modellerinden, kelimelerin anlamsal iliÅŸkilerini yakalayan **yoÄŸun (dense) vektÃ¶r** yani **Word Embedding** yÃ¶ntemlerine geÃ§iÅŸ yapacaÄŸÄ±z.

---

## ğŸ¯ Ã–ÄŸrenme Hedefleri
- Seyrek ve yoÄŸun metin temsil yÃ¶ntemleri arasÄ±ndaki temel farklarÄ± anlamak
- **Bag-of-Words (BoW)** ve **TF-IDF** gibi frekans tabanlÄ± modelleri uygulamak ve yorumlamak
- **Word2Vec (CBOW & Skip-gram)** ve **GloVe** gibi kelime gÃ¶mme (word embedding) modellerinin ardÄ±ndaki temel mantÄ±ÄŸÄ± kavramak
- `gensim` kÃ¼tÃ¼phanesini kullanarak Ã¶zel bir TÃ¼rkÃ§e korpus (`hurriyet.txt`) Ã¼zerinde **Word2Vec modeli** eÄŸitmek
- Ã–nceden eÄŸitilmiÅŸ **GloVe** kelime vektÃ¶rlerini yÃ¼klemek ve anlamsal analizlerde kullanmak
- Metin temsil yÃ¶ntemlerini, duygu analizi gibi gerÃ§ek dÃ¼nya problemlerine uygulamak (`IMDB Dataset.csv`)

---

## ğŸ“‚ KlasÃ¶r YapÄ±sÄ± ve Ä°Ã§erik
- `01.Text Representations.ipynb` â†’ **Teorik Temeller:** BoW ve TF-IDF gibi temel vektÃ¶rleÅŸtirme tekniklerinin matematiksel altyapÄ±sÄ±nÄ± ve pratik implementasyonlarÄ±nÄ± iÃ§eren baÅŸlangÄ±Ã§ noktasÄ±.
- `02-Word2vec and GloVe.ipynb` â†’ **Derinlemesine Uygulama:** Anlamsal temsillerin gÃ¼cÃ¼nÃ¼ keÅŸfedeceÄŸimiz, `gensim` ile Ã¶zel model eÄŸitimi ve Ã¶nceden eÄŸitilmiÅŸ GloVe vektÃ¶rlerinin analizi.
- `03 - Case 2 Solution.ipynb` â†’ **Sentez ve Analiz:** HaftanÄ±n tÃ¼m konularÄ±nÄ± birleÅŸtiren, Ã¶rnek bir metin verisi Ã¼zerinde farklÄ± metin temsil stratejilerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran kapsamlÄ± vaka analizi.
- `IMDB Dataset.csv` â†’ Vaka Ã§alÄ±ÅŸmamÄ±zÄ±n temelini oluÅŸturan, pozitif ve negatif film yorumlarÄ±nÄ± iÃ§eren zengin veri seti.
- `hurriyet.txt` â†’ TÃ¼rkÃ§e NLP yeteneklerimizi test etmek ve Ã¶zelleÅŸtirilmiÅŸ bir model eÄŸitmek iÃ§in kullanacaÄŸÄ±mÄ±z yerel metin korpusu.
- `glove.6B.100d.txt` â†’ Milyarlarca kelime Ã¼zerinde eÄŸitilmiÅŸ, transfer Ã¶ÄŸrenme (transfer learning) iÃ§in kullanÄ±lacak endÃ¼stri standardÄ± GloVe kelime vektÃ¶rleri.

---

## ğŸ”¬ Konular
- **Seyrek Temsiller (Sparse Representations)**
  - Bag of Words (BoW)
  - TF-IDF (Term Frequency-Inverse Document Frequency)
  - N-Gram Modellemesi ile BaÄŸlam ZenginleÅŸtirme

- **YoÄŸun Temsiller (Dense Representations): Word Embeddings**
  - Word2Vec Mimarisi: CBOW ve Skip-gram
  - GloVe: Global Vectors for Word Representation
  - Ã–nceden EÄŸitilmiÅŸ (Pre-trained) Modellerin KullanÄ±mÄ±

- **UygulamalÄ± Ã‡alÄ±ÅŸma (Case Study)**
  - `IMDB Dataset.csv` Ã¼zerinde duygu analizi (sentiment analysis)
  - FarklÄ± metin temsil yÃ¶ntemlerinin model performansÄ±na etkisinin karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
  - TÃ¼rkÃ§e bir korpus (`hurriyet.txt`) ile sÄ±fÄ±rdan Word2Vec modeli eÄŸitimi

---

## ğŸ› ï¸ Teknoloji YÄ±ÄŸÄ±nÄ± (Tech Stack)
- **Python 3.11+** & **Jupyter Notebook**
- **Veri ManipÃ¼lasyonu:** `pandas`, `numpy`
- **Klasik ML & NLP:** `scikit-learn` (BoW, TF-IDF, Modelleme iÃ§in)
- **Word Embedding:** `gensim` (Word2Vec eÄŸitimi ve yÃ¶netimi iÃ§in endÃ¼stri standardÄ±)
- **YardÄ±mcÄ± KÃ¼tÃ¼phaneler:** `nltk` (Metin Ã¶n iÅŸleme iÃ§in)
- **Veri GÃ¶rselleÅŸtirme:** `matplotlib`, `seaborn` (SonuÃ§larÄ±n ve vektÃ¶r uzaylarÄ±nÄ±n gÃ¶rsel analizi iÃ§in)

---

## ğŸ“Š Beklenen Ã‡Ä±ktÄ±lar
- Metin verisini BoW ve TF-IDF matrislerine dÃ¶nÃ¼ÅŸtÃ¼rme
- Ã–zel bir korpus ile Word2Vec modeli eÄŸitme ve kelimeler arasÄ± anlamsal benzerlikleri keÅŸfetme
- Ã–nceden eÄŸitilmiÅŸ GloVe vektÃ¶rlerini kullanarak kelime analojilerini (Ã¶r: kral - erkek + kadÄ±n = kraliÃ§e) test etme
- FarklÄ± metin temsil yÃ¶ntemlerinin duygu analizi performansÄ± Ã¼zerindeki etkisini karÅŸÄ±laÅŸtÄ±ran bir analiz raporu

---

ğŸ“Œ Bu hafta Ã¶ÄŸrendiÄŸimiz yoÄŸun vektÃ¶r temsilleri (word embeddings), sonraki haftalarda ele alacaÄŸÄ±mÄ±z **Transformer tabanlÄ± modern NLP modelleri (BERT, GPT)** ve bu modellerin temelini oluÅŸturan **dikkat mekanizmalarÄ± (attention mechanism)** iÃ§in kritik bir altyapÄ± saÄŸlayacaktÄ±r.
